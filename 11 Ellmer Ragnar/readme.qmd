---
title: "Read Me!"
format: 
  gfm:
    toc: true
    toc-depth: 3
editor: source
---

# Mukadimah

*Workshop* kali ini kita akan membahas tentang LLM di **R**, mulai dari LLM *open source* dari **Huggingface** hingga LLM komersial seperti **OpenAI** dan **DeepSeek**.

Apa saja yang bisa dilakukan menggunakan LLM?

1.  *Text clustering*.
2.  *Retrieval augmented generation* (_RAG_).
3.  _Sentiment analysis_,
4. *and many more*.

# **Ellmer** dan **Ragnar**

Kita akan *exploit* kegunaan `ellmer` dan `ragnar` pada *workshop* ini. Pastikan sudah ter-*install* dan kita memiliki salah satu dari **API Key** **DeepSeek** atau **OpenAI**.

# *Setting* Awal _Python_ di __R__ untuk _Huggingface_

Sebelum mulai, kita memerlukan *setting* awal khusus agar bisa melakukan komputasi model **Huggingface** di *local computer* menggunakan **R**, kita perlu membuat *virtual python environment* dengan cara sebagai berikut:

## Tahap 1

Masuk ke `terminal` sebagai *super user*.

```         
sudo su
```

## Tahap 2

Pastikan *python* sudah ter-*install* lalu lakukan *update* sebagai berikut:

```         
# kita update dan upgrade sistem linux nya
apt update
apt upgrade -y

# kita akan install python3 environment terlebih dahulu
apt install python3-venv
python3 -m venv .env
source .env/bin/activate
```

## Tahap 3

*Install library* `transformers` pada *local computer* sebagai berikut:

```         
# proses install transformers dan torch
pip install keras
pip install tensorflow
pip install transformers
pip install sentence-transformers
pip install 'transformers[torch]'
pip install diffusers["torch"] transformers
pip install tf-keras
pip install duckdb
```

Saya melakukan instalasi menggunakan perintah `pip`. Jadi pastikan `pip` sudah ter-*install* terlebih dahulu.

## Catatan Khusus

Hal ini perlu dilakukan ulang setiap kali kita berpindah *working directory*.

# *Key Concept*

Untuk bisa melakukan *text analysis* ataupun **RAG**, ada satu ***step*** yang wajib dilakukan, yakni proses *embedding*.

## *Embedding*

Apa itu proses *embedding*?

*Embedding text* adalah proses transformasi teks menjadi representasi numerik (bisa berupa vektor atau matriks) yang menangkap makna semantik dan hubungan kontekstual. LLM menggunakan *embedding* untuk memetakan kata/frasa ke ruang vektor multidimensi dimana __jarak geometris mencerminkan kesamaan semantik__. Proses ini memungkinkan model memahami konteks, melakukan operasi matematika pada teks, dan mengidentifikasi pola tersembunyi dalam data linguistik.

```{r}
#| include: false

# library(nomnoml)
# 
# code <- '
# #direction: bottom
# [<start>] -> [<input>Input Teks] -> [Tokenization] -> [Embedding Layer]
# [Embedding Layer] -> [<database>Matrix Representation|Numerical Features] -> [<end>end]
# '
# 
# nomnoml(code)
```

![](flow.png){width="350"}

Contoh kasus:

Kalimat 1: Saya mau pergi ke pasar.

Kalimat 2: Saya mau pergi ke sekolah.

Menggunakan _embedding_ secara LLM, konteks dari kedua kalimat ini sangat berbeda dan __jarak geometris__-nya akan besar. Namun jika kita menggunakan teknik _indexing words_, jarak antar kedua kalimat sangat dekat.



